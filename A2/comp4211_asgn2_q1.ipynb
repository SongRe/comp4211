{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction of Q1\n",
        "In this question, you will utilize Torch to implement a Convolutional Neural Network (CNN) for performing digital number classification. You will download the well-known 'MNIST' dataset, which consists of 70,000 images. Among these, 60,000 images are used for training, and 10,000 images are reserved for testing. Each image in the dataset has a size of 28x28 pixels and represents a digit ranging from 0 to 9.\n",
        "\n",
        "The MNIST dataset is widely used in the field of machine learning and computer vision. It serves as a benchmark for evaluating algorithms and models for image classification tasks. The goal is to correctly classify the handwritten digits into their respective categories. By implementing a CNN, which is a type of neural network specifically designed for analyzing visual data, you'll be able to effectively classify the digits in the MNIST dataset."
      ],
      "metadata": {
        "id": "tp6TZqmBpUyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw0nuvfQTedk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "train_set = datasets.MNIST(\"./mnist/train\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_set = datasets.MNIST(\"./mnist/test\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "o7JhScndTf45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, val_indices, _, _ = train_test_split(\n",
        "    range(len(train_set)),\n",
        "    train_set.targets,\n",
        "    stratify=train_set.targets,\n",
        "    train_size=0.8,\n",
        ")\n",
        "\n",
        "# generate subset based on indices\n",
        "train_split = Subset(train_set, train_indices)\n",
        "val_split = Subset(train_set, val_indices)"
      ],
      "metadata": {
        "id": "A8pqIfQkTql6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_split, batch_size=128)\n",
        "val_loader = DataLoader(val_split, batch_size=128)\n",
        "test_loader = DataLoader(test_set, batch_size=128)"
      ],
      "metadata": {
        "id": "LUeWNiZwVUDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "pvMfrWf1VZWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, output_size):\n",
        "    super(CNN, self).__init__()\n",
        "    \"\"\"\n",
        "        Begining of of Implement\n",
        "        define the CNN network following these requirements:\n",
        "        1. Implement self.conv1/2/3, self.pool1/2/3 with channel numbers 16, 32, 64 respectively, using kernel sizes 3, 4, 2 respectively (stride=1 and padding=0).\n",
        "        2. Use MaxPool with a shape of (2, 2) for self.pool1/2/3.\n",
        "        3. Add a hidden linear layer with 1000 neurons before the output layer.\n",
        "        4. Set self.output as the softmax operator.\n",
        "    \"\"\"\n",
        "    # your code here\n",
        "\n",
        "    \"\"\"\n",
        "        End of Implement\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batchsize = x.shape[0]\n",
        "    \"\"\"\n",
        "        Begining of of Implement\n",
        "        excecute the forward step:\n",
        "        1. Use ReLU activation after convolution and before pooling.\n",
        "        2. Reshape the data before feeding it into the linear layer.\n",
        "        3. Output the results using self.output.\n",
        "\n",
        "    \"\"\"\n",
        "    # your code here\n",
        "    return x\n",
        "\n",
        "    \"\"\"\n",
        "        End of Implement\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "mhBShSjuVbeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "Please calculate the total trainable parameter size of the above network  architecture: (fill in this blank)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "n7H0Xdm0B5dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, n_epochs):\n",
        "    train_acc, val_acc = [], []\n",
        "    for epoch in range(n_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        correct, total = 0, 0\n",
        "        for idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            \"\"\"\n",
        "            Begining of of Implement\n",
        "            excecute the forward computation:\n",
        "            1. get the model outputs -> variable 'outputs';\n",
        "            2. change the format of labels to one hot -> variable 'labels_onehot';\n",
        "            3. compute loss -> variable 'loss'\n",
        "            \"\"\"\n",
        "            # your code here\n",
        "\n",
        "            \"\"\"\n",
        "            End of Implement\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            Begining of of Implement\n",
        "            do the optimization step:\n",
        "            1. clean the old/previous gradient;\n",
        "            2. compute the current gradient (backward propagation)\n",
        "            3. update the parameter\n",
        "            \"\"\"\n",
        "\n",
        "            # your code here\n",
        "\n",
        "            \"\"\"\n",
        "            End of Implement\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            Begining of of Implement\n",
        "            get the predicted labels of the training data from variable 'outputs' -> variable 'predicted'\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            # your code here\n",
        "\n",
        "            \"\"\"\n",
        "            End of Implement\n",
        "            \"\"\"\n",
        "\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            if idx % 100 == 0:\n",
        "                print(f\"epoch: {epoch}, loss: {loss:.2f}, train_acc: {(correct/total):.2f}\")\n",
        "\n",
        "        train_acc.append(correct/total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                \"\"\"\n",
        "                Begining of of Implement\n",
        "                1. get the model outputs -> variable 'outputs';\n",
        "                2. get the predicted labels -> predicted\n",
        "                \"\"\"\n",
        "\n",
        "                # your code here\n",
        "\n",
        "                \"\"\"\n",
        "                End of Implement\n",
        "                \"\"\"\n",
        "\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        val_acc.append(correct/total)\n",
        "\n",
        "    return train_acc, val_acc"
      ],
      "metadata": {
        "id": "_t7XHUuoXlZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing function\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            \"\"\"\n",
        "            Begining of of Implement\n",
        "            1. get the model outputs -> variable 'outputs';\n",
        "            2. get the predicted labels -> predicted\n",
        "            \"\"\"\n",
        "\n",
        "            # your code here\n",
        "\n",
        "            \"\"\"\n",
        "            End of Implement\n",
        "            \"\"\"\n",
        "\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "1x7eOqdiXqFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "output_size = 10\n",
        "n_epochs = 5\n",
        "lr = 0.001\n",
        "\n",
        "# Training, Validation, and Testing\n",
        "model = CNN(output_size).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train_acc, val_acc = train(model, criterion, optimizer, train_loader, val_loader, n_epochs)\n",
        "test_acc = test(model, test_loader)\n",
        "plt.plot(train_acc, label='Train Acc')\n",
        "plt.plot(val_acc, label='Val Acc')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(f'Test Acc: {test_acc}')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "etTRkB9bXs9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}